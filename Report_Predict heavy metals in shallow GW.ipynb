{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Tranghuynh\n",
    "'''1/4/2021 synthesize all tasks for J1'''\n",
    "##\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('E:/CURRENT PROJECTS/J1_check in-situ para/code/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer,StandardScaler,RobustScaler, KBinsDiscretizer\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report,r2_score, mean_squared_error,\n",
    "                             precision_score, multilabel_confusion_matrix,recall_score,f1_score,roc_auc_score,\n",
    "                             plot_roc_curve,log_loss)\n",
    "#\n",
    "from sklearn.preprocessing import LabelEncoder,KBinsDiscretizer\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "#\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#\n",
    "from yellowbrick.model_selection import feature_importances,FeatureImportances\n",
    "from sklearn.utils import resample\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.inspection import permutation_importance\n",
    "import function_all as fa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing steps\n",
    "#1. , remove missing column/row, low concentration metal, clean data by IQR\n",
    "#2. resample by time: Q, fill missing by median\n",
    "#3. clustering BDSCAN\n",
    "#4 select cluster, bootstrap sample by well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##5 descriptive summary data\n",
    "newpath='E:/CURRENT PROJECTS/J1_check in-situ para/revise_1/'\n",
    "df=pd.read_csv(newpath+ 'df030.csv')\n",
    "df.columns\n",
    "key=['T', 'D', 'EC', 'pH', 'TH', 'TDS', 'Cl', 'NH4',\n",
    "       'NO3', 'SO4', 'TOC','As', 'Mn','Fe']\n",
    "var=['Temperature','Depth to water','Electrical conductivity','pH','Total hardness','Total dissolved solids','Chloride salt',\n",
    "         'Ammonia Nitrogen','Nitrate Nitrogen', 'Sulfate','Total organic carbon','Arsenic', 'Manganese','Iron']\n",
    "a=fa.sumdata(df,key,var)\n",
    "print(a)\n",
    "#\n",
    "a.to_csv(newpath+'sumdf030_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##6 sprearman correlation\n",
    "\n",
    "var=['X','Y','T','D', 'EC', 'pH', 'TH', 'TDS', 'Cl', 'NH4','NO3', 'SO4', 'TOC','As','Fe','Mn']\n",
    "\n",
    "def heatmapcor(df,var,path,method,name):\n",
    "    dt=df[var]\n",
    "    corr_matrix = dt.corr(method=method)\n",
    "    mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "    mask_ut = np.triu(np.ones(corr_matrix.shape)).astype(np.bool)  # extract lower triangle matrix\n",
    "\n",
    "    # create figure\n",
    "    f, ax = plt.subplots(figsize=(5,5))\n",
    "    heatmap = sns.heatmap(corr_matrix,\n",
    "                          mask=mask_ut,\n",
    "                          square=True,\n",
    "                          linewidths=.5,\n",
    "                          cmap='coolwarm',\n",
    "                          cbar_kws={'shrink': .8,\n",
    "                                    'ticks': [-1, -.5, 0, 0.5, 1]},\n",
    "                          vmin=-1,\n",
    "                          vmax=1,\n",
    "                          annot=True,\n",
    "                          annot_kws={'size': 4}\n",
    "                          )\n",
    "\n",
    "    # add the column names as labels\n",
    "    ticks = np.arange(corr_matrix.shape[0]) + 0.5\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(corr_matrix.columns, rotation=90, fontsize=8)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(corr_matrix.index, rotation=360, fontsize=8)\n",
    "    #\n",
    "    plt.savefig(path + str(name)+'_spearman_Hmap.png', format='png', dpi=2000)\n",
    "\n",
    "heatmapcor(df,var,newpath,'spearman','df030')\n",
    "\n",
    "\n",
    "## plot scatter by location\n",
    "sns.lmplot(data=df, x='X', y='Y', hue='Cluster',height=6, aspect=.8,\n",
    "                   fit_reg=False, legend=True, legend_out=True, palette=\"Set1\")\n",
    "plt.savefig(newpath + 'Cluster distribution TDS-year.png', format='png', dpi=1000)\n",
    "#plot variable by time an cluster\n",
    "\n",
    "sns.lmplot(data=df1, x='year', y='TDS', hue='Cluster',height=6, aspect=.8,\n",
    "                   fit_reg=False, legend=True, legend_out=True, palette=\"Set1\")\n",
    "\n",
    "plt.xticks(np.arange(min(df1['year']),max(df1['year'])+1,5))\n",
    "plt.savefig(newpath + 'Cluster distribution TDS-year.png', format='png', dpi=1000)\n",
    "##group max value by cluster\n",
    "df=pd.read_csv(newpath+'df_cluster.csv')\n",
    "b=df.groupby('Cluster')['T','D', 'EC', 'pH', 'TH', 'TDS', 'Cl', 'NH4','NO3', 'SO4', 'TOC','As','Fe','Mn'].max()\n",
    "print(b)\n",
    "#b.to_csv(newpath+'cluster_max.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##7. run bootstrap model selection + plot\n",
    "features=['X','Y','T','D', 'EC', 'pH', 'TH', 'TDS', 'Cl', 'NH4','NO3', 'SO4', 'TOC']\n",
    "targets=['Fe','Mn','As']\n",
    "scale=MinMaxScaler()\n",
    "\n",
    "# prepare models in list\n",
    "models = []\n",
    "models.append(('MLP', MLPRegressor(hidden_layer_sizes=(20,10),learning_rate_init=0.01,max_iter=2000,\n",
    "                                 early_stopping=True)))\n",
    "models.append(('RFR',RandomForestRegressor()))\n",
    "models.append(('KNR', KNeighborsRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('LR',LinearRegression()))\n",
    "models.append(('GBR',GradientBoostingRegressor()))\n",
    "# configure bootstrap sampling then predicting\n",
    "n_iter = 100\n",
    "n_size = 0.75\n",
    "scaler=MinMaxScaler()\n",
    "result1=fa.bootstrap_nmodel_ktarget(df,features,targets,n_iter,n_size,scaler,models) #model in list, not dict\n",
    "result1.to_csv(newpath+'model_boots_df030.csv')\n",
    "\n",
    "#boxplot compare train and test by each model\n",
    "out=pd.read_csv(newpath+'model_boots_df030.csv')\n",
    "name=out['Target'].unique()\n",
    "#outFe=out[out['Target']=='Fe']\n",
    "for i in name:\n",
    "    fig, g = plt.subplots(figsize=(6,4))\n",
    "    out1=out[out['Target']==i]\n",
    "    out2=out1[['Models','RMSE train','RMSE test']]\n",
    "    show=pd.melt(out2,id_vars='Models')\n",
    "    g=sns.boxplot(x='Models',y='value',hue='variable',data=show,palette={'RMSE train': 'salmon',\n",
    "                         'RMSE test':'deepskyblue'})\n",
    "    #g.legend(loc='center right',bbox_to_anchor=(1.2,0.5))\n",
    "    plt.savefig(newpath+ str(i)+'_select_model.png',format='png',dpi=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. run optimization: 3.1 tuning\n",
    "model=RandomForestRegressor()\n",
    "for t in targets:\n",
    "    start_time = time.time()\n",
    "    result,bestmodel =fa.tune_RFR(model,df,features,t,n_iter,n_size,cv,scaler,rd_state=42)\n",
    "    pickle.dump(bestmodel, open(newpath+str(t)+'_model_df030', 'wb'))\n",
    "    end_time = time.time()\n",
    "    print(f'model ran for {round((end_time -  start_time)/60.0, 2)} minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. run FPI: 3.2\n",
    "# 10 select group features based on max_feature and FPI-> run boostrap feature selection + plot\n",
    "# 11. run UQ + show intervals\n",
    "# 12. run treeintepreter + show boxplot comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
