{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('E:/CURRENT PROJECTS/J1_check in-situ para/code/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.target.feature_correlation import feature_correlation\n",
    "from sklearn.metrics import (r2_score, mean_absolute_error, mean_squared_error,explained_variance_score,\n",
    "                             accuracy_score, f1_score, recall_score, precision_score)\n",
    "\n",
    "from yellowbrick.features import rank1d, rank2d\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from yellowbrick.model_selection import feature_importances\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis,skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumdata(df,key,var): #key variables\n",
    "    global sumdf\n",
    "    dict = {k: v for k, v in zip(key, var)}\n",
    "    sumdf=pd.DataFrame({'Variables': [],'Description':[], 'Min':[], 'Max':[], 'Mean':[],'STD':[], 'Ske':[],'Kur':[]})\n",
    "    for key in dict:\n",
    "        v=dict[key]\n",
    "        ab=key\n",
    "        min=df[key].min()\n",
    "        max=df[key].max()\n",
    "        mean=('%.3f' % df[key].mean())\n",
    "        std=('%.3f ' % df[key].std())\n",
    "        ske=('%.3f ' % skew(df[key], axis = 1, bias = True))\n",
    "        kur=('%.3f ' % kurtosis(df[key], axis = 0, fisher = True, bias = True))\n",
    "        sumdf = sumdf.append({'Variables': ab, 'Description': v, 'Min': min, 'Max': max, 'Mean':mean,'STD':std,'Ske':ske,'Kur':kur},ignore_index=True)\n",
    "    print(sumdf)\n",
    "    return sumdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def bootstrap_nmodel_ktarget(df,features,targets,n_iterations,n_size,scale,nmodels): #model in list, not dict\n",
    "    # bootstrap sampling\n",
    "    global result\n",
    "    result = pd.DataFrame({'Target':[],'Iteration':[],'Models': [],'runtime_s':[], 'R2 train': [], 'RMSE train': [], 'R2 test': [],'RMSE test': []})\n",
    "    for k in targets:\n",
    "        for i in range(n_iterations):\n",
    "            print(i)\n",
    "        # prepare train and test sets\n",
    "            train, test = train_test_split(df, train_size=n_size,random_state=i)\n",
    "            X_train = scale.fit_transform(train[features])\n",
    "            y_train = train[k]\n",
    "            X_test = scale.transform(test[features])\n",
    "            y_test = test[k]\n",
    "            # fit model\n",
    "            for m, model in nmodels:\n",
    "                start_time = time.time()\n",
    "                model.fit(X_train, y_train)\n",
    "                pred1 = model.predict(X_train)\n",
    "                pred2 = model.predict(X_test)\n",
    "                end_time = time.time()\n",
    "                runtime= end_time - start_time\n",
    "                r1 = ('%.3f' % r2_score(y_train, pred1))\n",
    "                r2 = ('%.3f' % r2_score(y_test, pred2))\n",
    "                rmse1 = ('%.3f' % mean_squared_error(y_train, pred1, squared=False))\n",
    "                rmse2 = ('%.3f' % mean_squared_error(y_test, pred2, squared=False))\n",
    "                result = result.append(\n",
    "                    {'Target':k,'Iteration': i, 'Models': m,'runtime_s':runtime, 'R2 train': r1, 'RMSE train': rmse1, 'R2 test': r2,\n",
    "                     'RMSE test': rmse2}, ignore_index=True)\n",
    "    print('done!\\n', result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_RFR(model,df,features,target,n_iter,n_size,cv,scaler, rd_state):\n",
    "    global result, bestmodel\n",
    "    n_estimators = [int(x) for x in np.linspace(start=500, stop=2000, num=100)]\n",
    "    max_depth = [int(x) for x in np.linspace(5,15, num=10)]\n",
    "    min_samples_split = [int(x) for x in np.linspace(4, 20, num=8)]\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(4, 20, num=8)]\n",
    "    max_features=[int(x) for x in range(5, len(features)+1,1)]\n",
    "    #oob_score=[True]\n",
    "    #max_samples=[int(x) for x in np.linspace(20, 500, num=20)]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'max_features':max_features\n",
    "                                                         }\n",
    "    print(random_grid)\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = getsplit_rd(X, y,n_size,scaler,rd_state)\n",
    "    search = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=n_iter, cv=cv,\n",
    "                                random_state=rd_state, verbose=1, n_jobs=-1)\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    bestmodel = search.best_estimator_\n",
    "    result=fitted_model_val(bestmodel, X_train, X_test, y_train, y_test)\n",
    "    print(' bestmodel\\n',search.best_params_)\n",
    "    return result, bestmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncertainty\n",
    "def df_actual_Qpred(model,quantiles,X_test,y_test,path,name):\n",
    "    '''create dataframe of quantile prediction'''\n",
    "    pred_Q = pd.DataFrame()\n",
    "    for pred in model.estimators_:\n",
    "        temp = pd.Series(pred.predict(X_test).round(2))\n",
    "        pred_Q = pd.concat([pred_Q, temp], axis=1)\n",
    "    print(pred_Q.head())\n",
    "    RF_actual_pred = pd.DataFrame()\n",
    "    for q in quantiles:\n",
    "        s = pred_Q.quantile(q=q, axis=1)\n",
    "        RF_actual_pred = pd.concat([RF_actual_pred, s], axis=1, sort=False)\n",
    "    RF_actual_pred.columns = quantiles\n",
    "    RF_actual_pred['actual'] = y_test.to_list()\n",
    "    RF_actual_pred['interval'] = RF_actual_pred[np.max(quantiles)] - RF_actual_pred[np.min(quantiles)]\n",
    "    #RF_actual_pred = RF_actual_pred.sort_values('interval')\n",
    "    RF_actual_pred = RF_actual_pred.round(2)\n",
    "    print(RF_actual_pred.head())\n",
    "    RF_actual_pred.to_csv(path + str(name)+ '_RF_pred.csv')\n",
    "    return RF_actual_pred\n",
    "\n",
    "def correctPcnt(df_actual_Qpred,Qlow,Qhigh):\n",
    "    correct = 0\n",
    "    for i in range(df_actual_Qpred.shape[0]):\n",
    "        if df_actual_Qpred.loc[i, Qlow] <= df_actual_Qpred.loc[i, 'actual'] <= df_actual_Qpred.loc[i, Qhigh]:\n",
    "            correct += 1\n",
    "    print('Correct percentage: %.2f' % (correct / len(df_actual_Qpred)*100))\n",
    "\n",
    "def showIntervals(df,df_show,Qlow,Qhigh,path,name):\n",
    "    '''create plot of ytrue, y quantile of df_show for 100 st samples, score of all test\n",
    "    '''\n",
    "    plt.rcParams['axes.labelsize'] = 10\n",
    "    plt.rcParams['axes.titlesize'] = 10\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    fig, ax = plt.subplots(figsize=(4,5))\n",
    "\n",
    "    ax.plot(df_show['actual'], 'go', markersize=3, label='Actual',color='b')\n",
    "    ax.plot(df_show['0.5'],linewidth=0.8,  label='Median prediction',color='k')\n",
    "    ax.fill_between(\n",
    "        np.arange(df_show.shape[0]), df_show[Qlow], df_show[Qhigh], alpha=0.5, color=\"r\",\n",
    "        label=\"90% prediction interval\")\n",
    "    ax.set_xlabel(\"first 100 samples\")\n",
    "    ax.set_ylabel(\"Concentration (mg/l)\")\n",
    "    plt.xlim([0, len(df_show)+2])\n",
    "    plt.ylim([0, (df_show['actual'].max()*1.1)])\n",
    "    plt.legend()\n",
    "    plt.title(' $R^2$= %.2f'% r2_score(df['actual'] , df['0.5'])\n",
    "               + '; RMSE= %.3f ' % mean_squared_error(df['actual'], df['0.5'], squared=False)\n",
    "               )\n",
    "       #plt.text(1, 4, r'$R^2$=%.2f, RMSE=%.3f ' % (r2_score(df_actual_Qpred['actual'], df_actual_Qpred[0.5]),mean_squared_error(df_actual_Qpred['actual'], df_actual_Qpred[0.5], squared=False)))\n",
    "    plt.grid(b=None)\n",
    "    plt.show()\n",
    "    plt.savefig(path + str(name) + '_PI pred.png', format='png', dpi=2000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
